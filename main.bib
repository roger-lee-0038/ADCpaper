@article{yip_resolution-reconfigurable_2013,
	title = {A {Resolution}-{Reconfigurable} 5-to-10-{Bit} 0.4-to-1 {V} {Power} {Scalable} {SAR} {ADC} for {Sensor} {Applications}},
	volume = {48},
	issn = {0018-9200, 1558-173X},
	url = {http://ieeexplore.ieee.org/document/6496154/},
	doi = {10.1109/JSSC.2013.2254551},
	abstract = {A power-scalable SAR ADC for sensor applications is presented. The ADC features a reconﬁgurable 5-to-10-bit DAC whose power scales exponentially with resolution. At low resolutions where noise and linearity requirements are reduced, supply voltage scaling is leveraged to further reduce the energy-per-conversion. The ADC operates up to 2 MS/s at 1 V and 5 kS/s at 0.4 V, and its power scales linearly with sample rate down to leakage levels of 53 nW at 1 V and 4 nW at 0.4 V. Leakage power-gating during a SLEEP mode in between conversions reduces total power by up to 14\% at sample rates below 1 kS/s. Prototyped in a lowpower 65 nm CMOS process, the ADC in 10-bit mode achieves an INL and DNL of 0.57 LSB and 0.58 LSB respectively at 0.6 V, and the Nyquist SNDR and SFDR are 55 dB and 69 dB respectively at 0.55 V and 20 kS/s. The ADC achieves an optimal FOM of 22.4 fJ/conversion-step at 0.55 V in 10-bit mode. The combined techniques of DAC resolution and voltage scaling maximize efﬁciency at low resolutions, resulting in an FOM that increases by only 7x over the 5-bit scaling range, improving upon a 32x degradation that would otherwise arise from truncation of bits from an ADC of ﬁxed resolution and voltage.},
	language = {en},
	number = {6},
	urldate = {2022-06-18},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Yip, Marcus and Chandrakasan, A. P.},
	month = jun,
	year = {2013},
	pages = {1453--1464},
	file = {Yip and Chandrakasan - 2013 - A Resolution-Reconfigurable 5-to-10-Bit 0.4-to-1 V.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\B5TXJ2UG\\Yip and Chandrakasan - 2013 - A Resolution-Reconfigurable 5-to-10-Bit 0.4-to-1 V.pdf:application/pdf},
}

@article{razavi_design_1992,
	title = {Design techniques for high-speed, high-resolution comparators},
	volume = {27},
	issn = {00189200},
	url = {http://ieeexplore.ieee.org/document/173122/},
	doi = {10.1109/4.173122},
	abstract = {This paper describes precision techniques for the design of comparators used in high-performance analog-to-digital converters employing parallel conversion stages. Following a review of conventional offset cancellation techniques, circuit designs achieving 12-b resolution in both BiCMOS and CMOS 5-V technologies are presented. The BiCMOS comparator consists of a preamplifier followed by two regenerative stages and achieves an offset of 200 pV at a 1O-MHZ clock rate while dissipating 1.7 mW. In the CMOS comparator offset cancellation is used in both a single-stage preamplifier and a subsequent latch to achieve an offset of less than 300 pV at comparison rates as high as 10 MHz, with a power dissipation of 1.8 m W.},
	language = {en},
	number = {12},
	urldate = {2022-05-30},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Razavi, B. and Wooley, B.A.},
	month = dec,
	year = {1992},
	pages = {1916--1926},
	file = {Razavi and Wooley - 1992 - Design techniques for high-speed, high-resolution .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\YYKQTRSP\\Razavi and Wooley - 1992 - Design techniques for high-speed, high-resolution .pdf:application/pdf},
}

@book{keating_low_2007,
	address = {New York, NY},
	title = {Low power methodology manual: for system-on-chip design},
	isbn = {978-0-387-71818-7 978-0-387-71819-4},
	shorttitle = {Low power methodology manual},
	language = {en},
	publisher = {Springer},
	editor = {Keating, Michael},
	year = {2007},
	note = {OCLC: ocn156812961},
	keywords = {Low voltage integrated circuits, Systems on a chip},
	file = {Keating - 2007 - Low power methodology manual for system-on-chip d.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\H8Y7CSV4\\Keating - 2007 - Low power methodology manual for system-on-chip d.pdf:application/pdf},
}

@article{kim_11-bit_2021,
	title = {11-bit {Column}-{Parallel} {Single}-{Slope} {ADC} {With} {First}-{Step} {Half}-{Reference} {Ramping} {Scheme} for {High}-{Speed} {CMOS} {Image} {Sensors}},
	volume = {56},
	issn = {0018-9200, 1558-173X},
	url = {https://ieeexplore.ieee.org/document/9366299/},
	doi = {10.1109/JSSC.2021.3059909},
	abstract = {A ﬁrst-step half-reference ramping (FHR) readout scheme is presented in this study for high frame rate CMOS image sensors (CISs). The proposed readout scheme enhances the conversion speed of a single-slope (SS) analog-to-digital converter (ADC) by applying a binary-weighted searching algorithm at the ﬁrst A/D conversion attempt. By effectively reducing the reference signal range, the proposed FHR readout scheme can reduce the number of A/D conversion steps in the SS ADC while maintaining the ADC performance. Furthermore, the proposed scheme is reversible to operate the conventional SS ADC algorithm, thus it preserves the structural advantages of the SS ADC. The proposed FHR scheme becomes more effective as the bit-depth of the ADC increases. A prototype CIS with a column-parallel 11-bit SS ADC was fabricated in a 0.11-$\mu$m 1P4M CIS process with a 2.9-$\mu$m pixel pitch. A maximum frame rate of 570 frames/s was achieved with a 1024 × 240 pixel resolution, corresponding to a 140.08 Mp/s pixel rate. Total power consumption was 57.2 mW under 2.8 V for pixel readout and 1.8 V for readout circuitry. When compared with the conventional 11-bit SS ADC, the proposed FHR scheme shortens the total A/D conversion time by 38.4\%. The prototype CIS demonstrated the ﬁgure of merits (FoM) of 0.84 e−·nJ and 0.41 e−·nJ/step.},
	language = {en},
	number = {7},
	urldate = {2022-05-30},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Kim, Hyeon-June},
	month = jul,
	year = {2021},
	pages = {2132--2141},
	file = {Kim - 2021 - 11-bit Column-Parallel Single-Slope ADC With First.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\LVQMWE6E\\Kim - 2021 - 11-bit Column-Parallel Single-Slope ADC With First.pdf:application/pdf},
}

@article{kim_area-efficient_2016,
	title = {An {Area}-{Efficient} and {Low}-{Power} 12-b {SAR}/{Single}-{Slope} {ADC} {Without} {Calibration} {Method} for {CMOS} {Image} {Sensors}},
	volume = {63},
	issn = {0018-9383, 1557-9646},
	url = {http://ieeexplore.ieee.org/document/7515162/},
	doi = {10.1109/TED.2016.2587721},
	abstract = {This paper presents an area-efﬁcient and low-power 12-b successive approximation register/single-slope analog-todigital converter (SAR/SS ADC) for CMOS image sensor (CIS) applications. The number of unit capacitors of the proposed SAR/SS ADC is reduced to 1/64th of that of a conventional 12-b SAR ADC using only a 6-b capacitor digital-to-analog converter (DAC) and the power consumption is reduced by sharing analog circuits between the SAR ADC and the SS ADC. In addition, the proposed ADC properly operates without using any calibration method as it is designed to be robust to inaccuracies in analog circuits by connecting the ramp signal to the bottom plate of the unit capacitor in the capacitor DAC. A 1936 × 840 pixel 60 frames/s CIS with the proposed SAR/SS ADCs was fabricated using a 90-nm CMOS process, and each readout channel with the proposed SAR/SS ADC occupies an area of 2.24 $\mu$m × 998 $\mu$m and consumes a power of 30 $\mu$W. The measurement results show that the SAR/SS ADC has a differential nonlinearity of −0.45/+0.84 LSB and an integral nonlinearity of −1.5/+0.74 LSB. In addition, the developed CIS has a temporal noise of 2.7 LSBrms and a column ﬁxed pattern noise of 0.07 LSB.},
	language = {en},
	number = {9},
	urldate = {2022-05-30},
	journal = {IEEE Transactions on Electron Devices},
	author = {Kim, Min-Kyu and Hong, Seong-Kwan and Kwon, Oh-Kyong},
	month = sep,
	year = {2016},
	pages = {3599--3604},
	file = {Kim et al. - 2016 - An Area-Efficient and Low-Power 12-b SARSingle-Sl.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\XUGHF7KR\\Kim et al. - 2016 - An Area-Efficient and Low-Power 12-b SARSingle-Sl.pdf:application/pdf},
}

@inproceedings{snoeij_18v_2005,
	address = {Kobe, Japan},
	title = {A 1.{8V} 3.{2$\mu$W} {Comparator} for {Use} in a {CMOS} {Imager} {Column}-{Level} {Single}-{Slope} {ADC}},
	isbn = {978-0-7803-8834-5},
	url = {http://ieeexplore.ieee.org/document/1466047/},
	doi = {10.1109/ISCAS.2005.1466047},
	abstract = {In this paper, a 1.8V 3.2$\mu$W comparator is presented. It features a hybrid offset compensation scheme and achieves over 60dB gain with an input offset below 150$\mu$V. The comparator is designed in a 0.18$\mu$m CMOS process and is specifically designed to be used as the key component of a column-level single-slope ADC of a CMOS imager. This ADC architecture is attractive because of its low noise, but so far this has come at the price of a relatively high power consumption. Using this comparator design, the power consumption of column-level single-slope ADCs can be reduced significantly.},
	language = {en},
	urldate = {2022-05-30},
	booktitle = {2005 {IEEE} {International} {Symposium} on {Circuits} and {Systems}},
	publisher = {IEEE},
	author = {Snoeij, M.F. and Theuwissen, A.J.P. and Huijsing, J.H.},
	year = {2005},
	pages = {6162--6165},
	file = {Snoeij et al. - 2005 - A 1.8V 3.2$\mu$W Comparator for Use in a CMOS Imager C.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\5CN4GLDE\\Snoeij et al. - 2005 - A 1.8V 3.2$\mu$W Comparator for Use in a CMOS Imager C.pdf:application/pdf},
}

@article{kleinfelder_10000_2001,
	title = {A 10000 frames/s {CMOS} digital pixel sensor},
	volume = {36},
	issn = {00189200},
	url = {http://ieeexplore.ieee.org/document/972156/},
	doi = {10.1109/4.972156},
	abstract = {A 352 288 pixel CMOS image sensor chip with perpixel single-slope ADC and dynamic memory in a standard digital 0.18- m CMOS process is described. The chip performs “snapshot” image acquisition, parallel 8-bit A/D conversion, and digital readout at continuous rate of 10 000 frames/s or 1 Gpixels/s with power consumption of 50 mW. Each pixel consists of a photogate circuit, a three-stage comparator, and an 8-bit 3T dynamic memory comprising a total of 37 transistors in 9.4 9.4 m with a fill factor of 15\%. The photogate quantum efficiency is 13.6\%, and the sensor conversion gain is 13.1 V/e . At 1000 frames/s, measured integral nonlinearity is 0.22\% over a 1-V range, rms temporal noise with digital CDS is 0.15\%, and rms FPN with digital CDS is 0.027\%. When operated at low frame rates, on-chip power management circuits permit complete powerdown between each frame conversion and readout. The digitized pixel data is read out over a 64-bit (8-pixel) wide bus operating at 167 MHz, i.e., over 1.33 GB/s. The chip is suitable for general high-speed imaging applications as well as for the implementation of several still and standard video rate applications that benefit from high-speed capture, such as dynamic range enhancement, motion estimation and compensation, and image stabilization.},
	language = {en},
	number = {12},
	urldate = {2022-05-30},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Kleinfelder, S. and {SukHwan Lim} and {Xinqiao Liu} and El Gamal, A.},
	month = dec,
	year = {2001},
	pages = {2049--2059},
	file = {Kleinfelder et al. - 2001 - A 10000 framess CMOS digital pixel sensor.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\R9YFL78R\\Kleinfelder et al. - 2001 - A 10000 framess CMOS digital pixel sensor.pdf:application/pdf},
}

@inproceedings{likamwa_energy_2013,
	address = {Taipei, Taiwan},
	title = {Energy characterization and optimization of image sensing toward continuous mobile vision},
	isbn = {978-1-4503-1672-9},
	url = {http://dl.acm.org/citation.cfm?doid=2462456.2464448},
	doi = {10.1145/2462456.2464448},
	abstract = {A major hurdle to frequently performing mobile computer vision tasks is the high power consumption of image sensing. In this work, we report the ﬁrst publicly known experimental and analytical characterization of CMOS image sensors. We ﬁnd that modern image sensors are not energy-proportional: energy per pixel is in fact inversely proportional to frame rate and resolution of image capture, and thus image sensor systems fail to provide an important principle of energy-aware system design: trading quality for energy efﬁciency.},
	language = {en},
	urldate = {2022-05-30},
	booktitle = {Proceeding of the 11th annual international conference on {Mobile} systems, applications, and services - {MobiSys} '13},
	publisher = {ACM Press},
	author = {LiKamWa, Robert and Priyantha, Bodhi and Philipose, Matthai and Zhong, Lin and Bahl, Paramvir},
	year = {2013},
	pages = {69},
	file = {LiKamWa et al. - 2013 - Energy characterization and optimization of image .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\G6M325ZZ\\LiKamWa et al. - 2013 - Energy characterization and optimization of image .pdf:application/pdf},
}

@article{lubana_digital_2018,
	title = {Digital {Foveation}: {An} {Energy}-{Aware} {Machine} {Vision} {Framework}},
	volume = {37},
	issn = {0278-0070, 1937-4151},
	shorttitle = {Digital {Foveation}},
	url = {https://ieeexplore.ieee.org/document/8493507/},
	doi = {10.1109/TCAD.2018.2858340},
	abstract = {In machine vision applications, imaging systems and analysis algorithms are generally interdependent and energy intensive. We describe a machine vision energy minimization framework in which imaging hardware and vision algorithms are co-designed and tightly integrated. Digital foveation is inspired by the human vision system, which uses a spatially varying sensing architecture to generate oculomotory feedback and capture a series of high-resolution images using the densely sampling fovea. A multiround process with bidirectional information ﬂow between camera hardware and analysis software optimizes energy consumption while preserving accuracy. By using existing hardware mechanisms, namely, row / column skipping, random access via readout circuitry, and frame preservation, digital foveation adapts to the chosen analysis algorithm. It aims to transmit and process only the necessary parts of the scene under consideration. This framework is general across a wide range of embedded machine vision applications and enables large improvements in energy efﬁciency. When evaluated for an embedded license plate recognition vision application, it reduces system energy consumption by 81.3\% with at most 0.65\% reduction in accuracy.},
	language = {en},
	number = {11},
	urldate = {2022-05-30},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Lubana, Ekdeep Singh and Dick, Robert P.},
	month = nov,
	year = {2018},
	pages = {2371--2380},
	file = {Lubana and Dick - 2018 - Digital Foveation An Energy-Aware Machine Vision .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\S3F8GUI7\\Lubana and Dick - 2018 - Digital Foveation An Energy-Aware Machine Vision .pdf:application/pdf},
}

@article{chiu_4-kb_2020,
	title = {A 4-{Kb} 1-to-8-bit {Configurable} {6T} {SRAM}-{Based} {Computation}-in-{Memory} {Unit}-{Macro} for {CNN}-{Based} {AI} {Edge} {Processors}},
	volume = {55},
	issn = {0018-9200, 1558-173X},
	url = {https://ieeexplore.ieee.org/document/9140004/},
	doi = {10.1109/JSSC.2020.3005754},
	abstract = {Previous SRAM-based computing-in-memory (SRAM-CIM) macros suffer small read margins for highprecision operations, large cell array area overhead, and limited compatibility with many input and weight conﬁgurations. This work presents a 1-to-8-bit conﬁgurable SRAM CIM unit-macro using: 1) a hybrid structure combining 6T-SRAM based in-memory binary product-sum (PS) operations with digital near-memory-computing multibit PS accumulation to increase read accuracy and reduce area overhead; 2) column-based placevalue-grouped weight mapping and a serial-bit input (SBIN) mapping scheme to facilitate reconﬁguration and increase array efﬁciency under various input and weight conﬁgurations; 3) a self-reference multilevel reader (SRMLR) to reduce read-out energy and achieve a sensing margin 2× that of the midpoint reference scheme; and 4) an input-aware bitline voltage compensation scheme to ensure successful read operations across various input-weight patterns. A 4-Kb conﬁgurable 6T-SRAM CIM unit-macro was fabricated using a 55-nm CMOS process with foundry 6T-SRAM cells. The resulting macro achieved access times of 3.5 ns per cycle (pipeline) and energy efﬁciency of 0.6–40.2 TOPS/W under binary to 8-b input/8-b weight precision.},
	language = {en},
	number = {10},
	urldate = {2022-05-30},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Chiu, Yen-Cheng and Zhang, Zhixiao and Chen, Jia-Jing and Si, Xin and Liu, Ruhui and Tu, Yung-Ning and Su, Jian-Wei and Huang, Wei-Hsing and Wang, Jing-Hong and Wei, Wei-Chen and Hung, Je-Min and Sheu, Shyh-Shyuan and Li, Sih-Han and Wu, Chih-I and Liu, Ren-Shuo and Hsieh, Chih-Cheng and Tang, Kea-Tiong and Chang, Meng-Fan},
	month = oct,
	year = {2020},
	pages = {2790--2801},
	file = {Chiu et al. - 2020 - A 4-Kb 1-to-8-bit Configurable 6T SRAM-Based Compu.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\G5XPT628\\Chiu et al. - 2020 - A 4-Kb 1-to-8-bit Configurable 6T SRAM-Based Compu.pdf:application/pdf},
}

@article{jung_crossbar_2022,
	title = {A crossbar array of magnetoresistive memory devices for in-memory computing},
	volume = {601},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04196-6},
	doi = {10.1038/s41586-021-04196-6},
	language = {en},
	number = {7892},
	urldate = {2022-05-30},
	journal = {Nature},
	author = {Jung, Seungchul and Lee, Hyungwoo and Myung, Sungmeen and Kim, Hyunsoo and Yoon, Seung Keun and Kwon, Soon-Wan and Ju, Yongmin and Kim, Minje and Yi, Wooseok and Han, Shinhee and Kwon, Baeseong and Seo, Boyoung and Lee, Kilho and Koh, Gwan-Hyeob and Lee, Kangho and Song, Yoonjong and Choi, Changkyu and Ham, Donhee and Kim, Sang Joon},
	month = jan,
	year = {2022},
	pages = {211--216},
	file = {Jung et al. - 2022 - A crossbar array of magnetoresistive memory device.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\PLHR8HYE\\Jung et al. - 2022 - A crossbar array of magnetoresistive memory device.pdf:application/pdf},
}

@misc{karunaratne_-memory_2020,
	title = {In-memory hyperdimensional computing},
	url = {http://arxiv.org/abs/1906.01548},
	abstract = {Hyperdimensional computing (HDC) is an emerging computational framework that takes inspiration from attributes of neuronal circuits such as hyperdimensionality, fully distributed holographic representation, and (pseudo)randomness. When employed for machine learning tasks such as learning and classification, HDC involves manipulation and comparison of large patterns within memory. Moreover, a key attribute of HDC is its robustness to the imperfections associated with the computational substrates on which it is implemented. It is therefore particularly amenable to emerging non-von Neumann paradigms such as in-memory computing, where the physical attributes of nanoscale memristive devices are exploited to perform computation in place. Here, we present a complete in-memory HDC system that achieves a near optimum trade-off between design complexity and classification accuracy based on three prototypical HDC related learning tasks, namely, language classification, news classification, and hand gesture recognition from electromyography signals. Comparable accuracies to software implementations are demonstrated, experimentally, using 760,000 phase-change memory devices performing analog in-memory computing.},
	language = {en},
	urldate = {2022-05-30},
	publisher = {arXiv},
	author = {Karunaratne, Geethan and Gallo, Manuel Le and Cherubini, Giovanni and Benini, Luca and Rahimi, Abbas and Sebastian, Abu},
	month = apr,
	year = {2020},
	note = {Number: arXiv:1906.01548
arXiv:1906.01548 [physics]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Emerging Technologies, Physics - Applied Physics},
	file = {Karunaratne et al. - 2020 - In-memory hyperdimensional computing.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\I8TAU2KY\\Karunaratne et al. - 2020 - In-memory hyperdimensional computing.pdf:application/pdf},
}

@article{chen_processing_2020,
	title = {Processing {Near} {Sensor} {Architecture} in {Mixed}-{Signal} {Domain} {With} {CMOS} {Image} {Sensor} of {Convolutional}-{Kernel}-{Readout} {Method}},
	volume = {67},
	issn = {1549-8328, 1558-0806},
	url = {https://ieeexplore.ieee.org/document/8835152/},
	doi = {10.1109/TCSI.2019.2937227},
	abstract = {In the era of Artiﬁcial Intelligence (AI), bio-inspired perceptual computing system design brings favorable opportunities, while still facing considerable challenges in the meantime. Especially for tasks of image recognition in power-limited visionbased Internet of Things (IoT) devices, energy constraints due to the end of Dennard scaling limit the performance of Neural Network (NN) algorithms on popular digital platforms, which would not reach the energy efﬁciency requirement for embedded AI applications. In this paper, a processing near sensor architecture in mixed-signal domain with CMOS Image Sensor (CIS) of convolutional-kernel-readout method is proposed. Visual data is collected from a smart CIS, which can realize maximum 5 × 5 kernel-readout with minimum one slide step for convolutional operations. The outputs of CIS are directly processed by analog processing units locating near CIS without the constraint of digital clock and bottleneck of Analog-to-Digital Converter (ADC). By analyzing the effects of analog noise on classiﬁcation accuracy, we further evaluate the fault-tolerance of the system to circuit noise and the device imperfection, such as mismatch and process variation. A mixed-signal visual perception chip is fabricated with a 32 × 32 image sensor and a Binarized Neural Network (BNN) processing array integrated with SMIC 180nm standard CMOS mixed-signal process. Measurement results show up to 545.4 GOPS/W energy efﬁciency with 1.8mW power consumption taking the advantages of ADC-free processing architecture.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Chen, Zhe and Liu, Xinjun and Yang, Huazhong and Zhu, Huifeng and Ren, Erxiang and Liu, Zheyu and Jia, Kaige and Luo, Li and Zhang, Xuan and Wei, Qi and Qiao, Fei},
	month = feb,
	year = {2020},
	pages = {389--400},
	file = {Chen et al. - 2020 - Processing Near Sensor Architecture in Mixed-Signa.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\TGBPBMM5\\Chen et al. - 2020 - Processing Near Sensor Architecture in Mixed-Signa.pdf:application/pdf},
}

@article{liu_ns-cim_2020,
	title = {{NS}-{CIM}: {A} {Current}-{Mode} {Computation}-in-{Memory} {Architecture} {Enabling} {Near}-{Sensor} {Processing} for {Intelligent} {IoT} {Vision} {Nodes}},
	volume = {67},
	issn = {1549-8328, 1558-0806},
	shorttitle = {{NS}-{CIM}},
	url = {https://ieeexplore.ieee.org/document/9061142/},
	doi = {10.1109/TCSI.2020.2984161},
	abstract = {In recent years, Neural networks (NNs) present vast potential for innovative applications. However, energy efﬁciency continues to remain a challenge in deploying NNs on the edge. In this context, computation-in-memory (CIM) architecture becomes an emerging trend in the area of energy-efﬁcient hardware design, because it reduces data movement of multiply-accumulate (MAC) computation signiﬁcantly. However, many recent works employ massive data converters to feed input data and transform output results, which may counteract the beneﬁts of in-memory processing. To tackle this limitation, we propose a combined architecture cooperating sensor with CIM macro to achieve local processing of sensory signals. Current-mode computing techniques are exploited to achieve high energy efﬁciency while eliminating data conversion overhead. Moreover, we thoroughly analyze the non-idealities of the proposed mixed-signal circuits and present a co-design scheme to mitigate these imperfections. We have fabricated a 2Kbit CIM macro in the proposed architecture with TSMC 65-nm technology. The fabricated chip achieved 60.6 TOPS/W energy efﬁciency while consuming 845.5 $\mu$W power and 0.3 mm2 core area, presenting a promising solution for energy-constrained edge devices.},
	language = {en},
	number = {9},
	urldate = {2022-05-30},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Liu, Zheyu and Ren, Erxiang and Qiao, Fei and Wei, Qi and Liu, Xinjun and Luo, Li and Zhao, Huichan and Yang, Huazhong},
	month = sep,
	year = {2020},
	pages = {2909--2922},
	file = {Liu et al. - 2020 - NS-CIM A Current-Mode Computation-in-Memory Archi.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\EDF4EDWV\\Liu et al. - 2020 - NS-CIM A Current-Mode Computation-in-Memory Archi.pdf:application/pdf},
}

@inproceedings{likamwa_redeye_2016,
	address = {Seoul, South Korea},
	title = {{RedEye}: {Analog} {ConvNet} {Image} {Sensor} {Architecture} for {Continuous} {Mobile} {Vision}},
	isbn = {978-1-4673-8947-1},
	shorttitle = {{RedEye}},
	url = {http://ieeexplore.ieee.org/document/7551398/},
	doi = {10.1109/ISCA.2016.31},
	abstract = {Continuous mobile vision is limited by the inability to efﬁciently capture image frames and process vision features. This is largely due to the energy burden of analog readout circuitry, data trafﬁc, and intensive computation. To promote efﬁciency, we shift early vision processing into the analog domain. This results in RedEye, an analog convolutional image sensor that performs layers of a convolutional neural network in the analog domain before quantization. We design RedEye to mitigate analog design complexity, using a modular column-parallel design to promote physical design reuse and algorithmic cyclic reuse. RedEye uses programmable mechanisms to admit noise for tunable energy reduction. Compared to conventional systems, RedEye reports an 85\% reduction in sensor energy, 73\% reduction in cloudlet-based system energy, and a 45\% reduction in computation-based system energy.},
	language = {en},
	urldate = {2022-05-30},
	booktitle = {2016 {ACM}/{IEEE} 43rd {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {LiKamWa, Robert and Hou, Yunhui and Gao, Yuan and Polansky, Mia and Zhong, Lin},
	month = jun,
	year = {2016},
	pages = {255--266},
	file = {LiKamWa et al. - 2016 - RedEye Analog ConvNet Image Sensor Architecture f.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\9HCHV9MC\\LiKamWa et al. - 2016 - RedEye Analog ConvNet Image Sensor Architecture f.pdf:application/pdf},
}

@misc{chen_asp_2016,
	title = {{ASP} {Vision}: {Optically} {Computing} the {First} {Layer} of {Convolutional} {Neural} {Networks} using {Angle} {Sensitive} {Pixels}},
	shorttitle = {{ASP} {Vision}},
	url = {http://arxiv.org/abs/1605.03621},
	abstract = {Deep learning using convolutional neural networks (CNNs) is quickly becoming the state-of-the-art for challenging computer vision applications. However, deep learning’s power consumption and bandwidth requirements currently limit its application in embedded and mobile systems with tight energy budgets. In this paper, we explore the energy savings of optically computing the ﬁrst layer of CNNs. To do so, we utilize bio-inspired Angle Sensitive Pixels (ASPs), custom CMOS diffractive image sensors which act similar to Gabor ﬁlter banks in the V1 layer of the human visual cortex. ASPs replace both image sensing and the ﬁrst layer of a conventional CNN by directly performing optical edge ﬁltering, saving sensing energy, data bandwidth, and CNN FLOPS to compute. Our experimental results (both on synthetic data and a hardware prototype) for a variety of vision tasks such as digit recognition, object recognition, and face identiﬁcation demonstrate a reduction in image sensor power consumption and data bandwidth from sensor to CPU, while achieving similar performance compared to traditional deep learning pipelines.},
	language = {en},
	urldate = {2022-05-30},
	publisher = {arXiv},
	author = {Chen, Huaijin and Jayasuriya, Suren and Yang, Jiyue and Stephen, Judy and Sivaramakrishnan, Sriram and Veeraraghavan, Ashok and Molnar, Alyosha},
	month = nov,
	year = {2016},
	note = {Number: arXiv:1605.03621
arXiv:1605.03621 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Presented in CVPR 2016 (oral), 10 pages, 12 figures. This new version corrects the comparison between imaging power for ASPs and a regular image sensor},
	file = {Chen et al. - 2016 - ASP Vision Optically Computing the First Layer of.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\ZHHBU3J4\\Chen et al. - 2016 - ASP Vision Optically Computing the First Layer of.pdf:application/pdf},
}

@article{xia_10-bit_2006,
	title = {A 10-bit 44-{MS}/s 20-{mW} {Configurable} {Time}-{Interleaved} {Pipeline} {ADC} for a {Dual}-{Mode} 802.11b/{Bluetooth} {Receiver}},
	volume = {41},
	issn = {0018-9200},
	url = {http://ieeexplore.ieee.org/document/1599522/},
	doi = {10.1109/JSSC.2005.864131},
	abstract = {This work presents a conﬁgurable time-interleaved pipeline architecture as an efﬁcient solution for the ADC design in high data rate multi-standard radios. The ADC is implemented in a 0.25- m BiCMOS process as part of an integrated dual mode 802.11b/Bluetooth direct conversion receiver. Its structure can be conﬁgured to accommodate the different sampling rate and dynamic range requirements of both standards. The different techniques employed at the system and circuit levels to optimize the power consumption are described. An on-line digital calibration scheme is also incorporated to assure the conversion linearity and reduce mismatch among the parallel branches. The proposed ADC is a switched-capacitor implementation occupying an area of 2.1 mm2. It achieves 60 dB/64 dB dynamic range at 44 MHz/11 MHz sampling frequency with a power consumption of 20.2 mW/14.8 mW for the 802.11b/Bluetooth baseband signals.},
	language = {en},
	number = {3},
	urldate = {2022-05-30},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Xia, B. and Valdes-Garcia, A. and Sanchez-Sinencio, E.},
	month = mar,
	year = {2006},
	pages = {530--539},
	file = {Xia et al. - 2006 - A 10-bit 44-MSs 20-mW Configurable Time-Interleav.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\YJBFA8H3\\Xia et al. - 2006 - A 10-bit 44-MSs 20-mW Configurable Time-Interleav.pdf:application/pdf},
}

@article{zhu_06_2013,
	title = {A 0.6 {V} 100 {KS}/s 8–10 b resolution configurable {SAR} {ADC} in 0.18 $\mu$m {CMOS}},
	volume = {75},
	issn = {0925-1030, 1573-1979},
	url = {http://link.springer.com/10.1007/s10470-013-0062-6},
	doi = {10.1007/s10470-013-0062-6},
	abstract = {A resolution conﬁgurable ultra-low power SAR ADC in 0.18 lm CMOS process is presented. The proposed ADC has maximum sampling rate of 100 KS/s with conﬁgurable resolution from 8 to 10 b and operates at a supply of 0.6 V. Two-stage bootstrapped switch and voltage boosting techniques are introduced to improve the performance of the ADC at low voltage. To reduce the power consumption of the analog components of the ADC, monotonic capacitor switching procedure and fully dynamic comparator are utilized. The implementation of dynamic logic further reduces the power of the digital circuits. Post-layout simulation results show that the proposed SAR ADC consumes 521 nW and achieves an SNDR of 60.54 dB at 10 b mode, resulting in an ultra-low ﬁgure-of-merit of 6.0 fJ/conversion-step. The ADC core occupies an active area of only 350 9 280 lm2.},
	language = {en},
	number = {2},
	urldate = {2022-05-30},
	journal = {Analog Integrated Circuits and Signal Processing},
	author = {Zhu, Zhangming and Xiao, Yu and Wang, Weitie and Wang, Qiyu and Yang, Yintang},
	month = may,
	year = {2013},
	pages = {335--342},
	file = {Zhu et al. - 2013 - A 0.6 V 100 KSs 8–10 b resolution configurable SA.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\RRKJ58DH\\Zhu et al. - 2013 - A 0.6 V 100 KSs 8–10 b resolution configurable SA.pdf:application/pdf},
}

@article{zhu_6--10-bit_2015,
	title = {A 6-to-10-{Bit} 0.5 {V}-to-0.9 {V} {Reconfigurable} 2 {MS}/s {Power} {Scalable} {SAR} {ADC} in 0.18 $\mu$m {CMOS}},
	volume = {62},
	issn = {1549-8328, 1558-0806},
	url = {http://ieeexplore.ieee.org/document/6998059/},
	doi = {10.1109/TCSI.2014.2377431},
	abstract = {An asynchronous successive approximation register (SAR) analog-to-digital converter (ADC) for sensor applications is presented. High linear and power efﬁcient switching scheme is proposed. The proposed low leakage latched dynamic cell in SAR logic and wide range conﬁgurable delay element extend the ﬂexibility of speed and resolution tradeoff. The ADC fabricated in 0.18 CMOS process covers 6–10 bit resolution and 0.5 V–0.9 V power supply range. At 10 bit mode and 0.5 V operation, the proposed SAR ADC achieves 56.36 dB SNDR and 67.96 dB SFDR with sampling rate up to 2 MS/s, corresponding to a ﬁgure-of-merit of 20.6 fJ/conversion-step. The proposed ADC core occupies an active area of about .},
	language = {en},
	number = {3},
	urldate = {2022-05-30},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Zhu, Zhangming and Qiu, Zheng and Liu, Maliang and Ding, Ruixue},
	month = mar,
	year = {2015},
	pages = {689--696},
	file = {Zhu et al. - 2015 - A 6-to-10-Bit 0.5 V-to-0.9 V Reconfigurable 2 MSs.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\9VT6C4HU\\Zhu et al. - 2015 - A 6-to-10-Bit 0.5 V-to-0.9 V Reconfigurable 2 MSs.pdf:application/pdf},
}

@inproceedings{park_energy-efficient_2018,
	address = {Los Angeles, CA},
	title = {Energy-{Efficient} {Neural} {Network} {Accelerator} {Based} on {Outlier}-{Aware} {Low}-{Precision} {Computation}},
	isbn = {978-1-5386-5984-7},
	url = {https://ieeexplore.ieee.org/document/8416865/},
	doi = {10.1109/ISCA.2018.00063},
	abstract = {Owing to the presence of large values, which we call outliers, conventional methods of quantization fail to achieve signiﬁcantly low precision, e.g., four bits, for very deep neural networks, such as ResNet-101. In this study, we propose a hardware accelerator, called the outlier-aware accelerator (OLAccel). It performs dense and low-precision computations for a majority of data (weights and activations) while efﬁciently handling a small number of sparse and highprecision outliers (e.g., amounting to 3\% of total data). The OLAccel is based on 4-bit multiply-accumulate (MAC) units and handles outlier weights and activations in a different manner. For outlier weights, it equips SIMD lanes of MAC units with an additional MAC unit, which helps avoid cycle overhead for the majority of outlier occurrences, i.e., a single occurrence in the SIMD lanes. The OLAccel performs computations using outlier activation on dedicated, high-precision MAC units. In order to avoid coherence problem due to updates from lowand high-precision computation units, both units update partial sums in a pipelined manner. Our experiments show that the OLAccel can reduce by 43.5\% (27.0\%), 56.7\% (36.3\%), and 62.2\% (49.5\%) energy consumption for AlexNet, VGG-16, and ResNet-18, respectively, compared with a 16-bit (8-bit) state-of-the-art zero-aware accelerator. The energy gain mostly comes from the memory components, the DRAM, and on-chip memory due to reduced precision.},
	language = {en},
	urldate = {2022-05-30},
	booktitle = {2018 {ACM}/{IEEE} 45th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	publisher = {IEEE},
	author = {Park, Eunhyeok and Kim, Dongyoung and Yoo, Sungjoo},
	month = jun,
	year = {2018},
	pages = {688--698},
	file = {Park et al. - 2018 - Energy-Efficient Neural Network Accelerator Based .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\YQT56AIR\\Park et al. - 2018 - Energy-Efficient Neural Network Accelerator Based .pdf:application/pdf},
}

@article{courbariaux_binaryconnect_nodate,
	title = {{BinaryConnect}: {Training} {Deep} {Neural} {Networks} with binary weights during propagations},
	abstract = {Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great beneﬁts to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and powerhungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.},
	language = {en},
	author = {Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
	pages = {9},
	file = {Courbariaux et al. - BinaryConnect Training Deep Neural Networks with .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\4MSY6TPH\\Courbariaux et al. - BinaryConnect Training Deep Neural Networks with .pdf:application/pdf},
}

@misc{li_ternary_2016,
	title = {Ternary {Weight} {Networks}},
	url = {http://arxiv.org/abs/1605.04711},
	abstract = {We introduce ternary weight networks (TWNs) - neural networks with weights constrained to +1, 0 and -1. The Euclidian distance between full (ﬂoat or double) precision weights and the ternary weights along with a scaling factor is minimized. Besides, a threshold-based ternary function is optimized to get an approximated solution which can be fast and easily computed. TWNs have stronger expressive abilities than recently proposed binary precision counterparts and are more effective than the latter. Meanwhile, TWNs achieve up to 16× or 32× model compression rate and need fewer multiplications compared with the full precision counterparts. Benchmarks on MNIST, CIFAR-10, and large scale ImageNet datasets show that the performance of TWNs is only slightly worse than the full precision counterparts but outperforms the analogous binary precision counterparts a lot.},
	language = {en},
	urldate = {2022-05-30},
	publisher = {arXiv},
	author = {Li, Fengfu and Zhang, Bo and Liu, Bin},
	month = nov,
	year = {2016},
	note = {Number: arXiv:1605.04711
arXiv:1605.04711 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 5 pages, 3 fitures, conference},
	file = {Li et al. - 2016 - Ternary Weight Networks.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\ANH6EHWA\\Li et al. - 2016 - Ternary Weight Networks.pdf:application/pdf},
}

@incollection{leibe_xnor-net_2016,
	address = {Cham},
	title = {{XNOR}-{Net}: {ImageNet} {Classification} {Using} {Binary} {Convolutional} {Neural} {Networks}},
	volume = {9908},
	isbn = {978-3-319-46492-3 978-3-319-46493-0},
	shorttitle = {{XNOR}-{Net}},
	url = {http://link.springer.com/10.1007/978-3-319-46493-0_32},
	abstract = {We propose two eﬃcient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNORNetworks. In Binary-Weight-Networks, the ﬁlters are approximated with binary values resulting in 32× memory saving. In XNOR-Networks, both the ﬁlters and the input to convolutional layers are binary. XNORNetworks approximate convolutions using primarily binary operations. This results in 58× faster convolutional operations (in terms of number of the high precision operations) and 32× memory savings. XNORNets oﬀer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary networks are simple, accurate, eﬃcient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classiﬁcation task. The classiﬁcation accuracy with a Binary-Weight-Network version of AlexNet is the same as the full-precision AlexNet. We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than 16 \% in top-1 accuracy. Our code is available at: http://allenai.org/plato/xnornet.},
	language = {en},
	urldate = {2022-05-30},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	doi = {10.1007/978-3-319-46493-0_32},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {525--542},
	file = {Rastegari et al. - 2016 - XNOR-Net ImageNet Classification Using Binary Con.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\BBQBEMXG\\Rastegari et al. - 2016 - XNOR-Net ImageNet Classification Using Binary Con.pdf:application/pdf},
}

@misc{courbariaux_binarized_2016,
	title = {Binarized {Neural} {Networks}: {Training} {Deep} {Neural} {Networks} with {Weights} and {Activations} {Constrained} to +1 or -1},
	shorttitle = {Binarized {Neural} {Networks}},
	url = {http://arxiv.org/abs/1602.02830},
	abstract = {We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efﬁciency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classiﬁcation accuracy. The code for training and running our BNNs is available on-line.},
	language = {en},
	urldate = {2022-05-30},
	publisher = {arXiv},
	author = {Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
	month = mar,
	year = {2016},
	note = {Number: arXiv:1602.02830
arXiv:1602.02830 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 11 pages and 3 figures},
	file = {Courbariaux et al. - 2016 - Binarized Neural Networks Training Deep Neural Ne.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\6HKJYG9L\\Courbariaux et al. - 2016 - Binarized Neural Networks Training Deep Neural Ne.pdf:application/pdf},
}

@misc{cai_deep_2017,
	title = {Deep {Learning} with {Low} {Precision} by {Half}-wave {Gaussian} {Quantization}},
	url = {http://arxiv.org/abs/1702.00953},
	abstract = {The problem of quantizing the activations of a deep neural network is considered. An examination of the popular binary quantization approach shows that this consists of approximating a classical non-linearity, the hyperbolic tangent, by two functions: a piecewise constant sign function, which is used in feedforward network computations, and a piecewise linear hard tanh function, used in the backpropagation step during network learning. The problem of approximating the ReLU non-linearity, widely used in the recent deep learning literature, is then considered. An halfwave Gaussian quantizer (HWGQ) is proposed for forward approximation and shown to have efﬁcient implementation, by exploiting the statistics of of network activations and batch normalization operations commonly used in the literature. To overcome the problem of gradient mismatch, due to the use of different forward and backward approximations, several piece-wise backward approximators are then investigated. The implementation of the resulting quantized network, denoted as HWGQ-Net, is shown to achieve much closer performance to full precision networks, such as AlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision networks, with 1-bit binary weights and 2-bit quantized activations.},
	language = {en},
	urldate = {2022-05-30},
	publisher = {arXiv},
	author = {Cai, Zhaowei and He, Xiaodong and Sun, Jian and Vasconcelos, Nuno},
	month = feb,
	year = {2017},
	note = {Number: arXiv:1702.00953
arXiv:1702.00953 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Cai et al. - 2017 - Deep Learning with Low Precision by Half-wave Gaus.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\3SENKHZ9\\Cai et al. - 2017 - Deep Learning with Low Precision by Half-wave Gaus.pdf:application/pdf},
}

@article{el-halwagy_100-mss5-gss_2018,
	title = {A 100-{MS}/s–5-{GS}/s, 13–5-bit {Nyquist}-{Rate} {Reconfigurable} {Time}-{Domain} {ADC}},
	volume = {26},
	issn = {1063-8210, 1557-9999},
	url = {https://ieeexplore.ieee.org/document/8412548/},
	doi = {10.1109/TVLSI.2018.2850806},
	abstract = {This paper presents a 65-nm CMOS Nyquist-rate reconﬁgurable time-based analog-to-digital converter (ADC). The time-domain nature of the ADC allows for efﬁcient hardware reuse and a wide range of reconﬁgurability. The ADC employs a reconﬁgurable time-to-digital converter (TDC) that can be conﬁgured as a high-resolution 1-ps correlated double sampling SAR-TDC for the high-resolution modes or as a 4× asynchronous time-interleaved ﬂash-TDC for the high sampling rate modes. The Nyquist-rate ADC supports continuous sampling rate variations from 100 MS/s to 5 GS/s providing 13–5-bit resolution with exponential power scaling from 8.4 to 22.3 mW, respectively. A programmable highly linear 1-bit folded voltagecontrolled oscillator is employed to provide the appropriate tuning characteristics for different sampling rate modes with high linearity. The ADC linearity is further enhanced using foreground digital calibration achieving ﬁgure-of-merit ranging from 14.6 to 196 fJ/conv.},
	language = {en},
	number = {10},
	urldate = {2022-06-04},
	journal = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	author = {El-Halwagy, Waleed and Mousavi, Pedram and Hossain, Masum},
	month = oct,
	year = {2018},
	pages = {1967--1979},
	file = {El-Halwagy et al. - 2018 - A 100-MSs–5-GSs, 13–5-bit Nyquist-Rate Reconfigu.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\2DDMWADR\\El-Halwagy et al. - 2018 - A 100-MSs–5-GSs, 13–5-bit Nyquist-Rate Reconfigu.pdf:application/pdf},
}

@article{nie_single_2020,
	title = {A {Single} {Slope} {ADC} {With} {Row}-{Wise} {Noise} {Reduction} {Technique} for {CMOS} {Image} {Sensor}},
	volume = {67},
	issn = {1549-8328, 1558-0806},
	url = {https://ieeexplore.ieee.org/document/9036882/},
	doi = {10.1109/TCSI.2020.2979321},
	abstract = {This paper presents a novel technique for single slope analog to digital converter (SSADC) to suppress the rowwise noise in CMOS image sensor. A sample switch is used in the current-steering DAC to reduce the noise introduced by bias circuits, which will deteriorate the characteristic of uniformity in the row direction. The sample switch can ﬁx the voltage which biases the current source in the current-steering DAC when generating a ramp to avoid the ramp ﬂuctuation in the time domain. The digital correlated double sampling is used to reduce the non-uniformity in column-level ADCs. The CMOS image sensor prototype is fabricated in 110nm 1P3M process. The 10-bit SSADC achieves DNL of −0.20 / +0.15 LSB and INL of −1.35 / +0.91 LSB at a sampling frequency of 29.2 KHz. It is proved that the row-wise noise is reduced from 764$\mu$Vrmsto 163$\mu$Vrmsat a frame rate of 228 fps using the proposed sample switch structure. The prototype photos taken by the sensor show that the row-wise noise is reduced under the low-illumination circumstance effectively.},
	language = {en},
	number = {9},
	urldate = {2022-06-08},
	journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
	author = {Nie, Kaiming and Zha, Wanbin and Shi, Xiaolin and Li, Jiawen and Xu, Jiangtao and Ma, Jianguo},
	month = sep,
	year = {2020},
	pages = {2873--2882},
	file = {Nie et al. - 2020 - A Single Slope ADC With Row-Wise Noise Reduction T.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\UBPZ2U4Y\\Nie et al. - 2020 - A Single Slope ADC With Row-Wise Noise Reduction T.pdf:application/pdf},
}

@inproceedings{kumagai_14-inch_2018,
	address = {San Francisco, CA},
	title = {A 1/4-inch 3.{9Mpixel} low-power event-driven back-illuminated stacked {CMOS} image sensor},
	isbn = {978-1-5090-4940-0},
	url = {http://ieeexplore.ieee.org/document/8310196/},
	doi = {10.1109/ISSCC.2018.8310196},
	language = {en},
	urldate = {2022-06-08},
	booktitle = {2018 {IEEE} {International} {Solid} - {State} {Circuits} {Conference} - ({ISSCC})},
	publisher = {IEEE},
	author = {Kumagai, Oichi and Niwa, Atsumi and Hanzawa, Katsuhiko and Kato, Hidetaka and Futami, Shinichiro and Ohyama, Toshio and Imoto, Tsutomu and Nakamizo, Masahiko and Murakami, Hirotaka and Nishino, Tatsuki and Bostamam, Anas and Iinuma, Takahiro and Kuzuya, Naoki and Hatsukawa, Kensuke and Brady, Frederick and Bidermann, William and Wakano, Toshifumi and Nagano, Takashi and Wakabayashi, Hayato and Nitta, Yoshikazu},
	month = feb,
	year = {2018},
	pages = {86--88},
	file = {Kumagai et al. - 2018 - A 14-inch 3.9Mpixel low-power event-driven back-i.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\NCQG7LW8\\Kumagai et al. - 2018 - A 14-inch 3.9Mpixel low-power event-driven back-i.pdf:application/pdf},
}

@article{park_640_2020,
	title = {A 640 $\times$ 640 {Fully} {Dynamic} {CMOS} {Image} {Sensor} for {Always}-{On} {Operation}},
	volume = {55},
	issn = {0018-9200, 1558-173X},
	url = {https://ieeexplore.ieee.org/document/8944068/},
	doi = {10.1109/JSSC.2019.2959486},
	abstract = {This article presents a 640 × 640 fully dynamic CMOS image sensor for the always-on operation. It consists of a dynamic pixel source follower (SF), whose output signal is sampled into a parasitic column capacitor and then read out by a dynamic single-slope (SS) analog-to-digital converter (ADC) based on a dynamic bias comparator and an energyefﬁcient two-step counter. The prototype sensor was implemented in a 110-nm CMOS process, achieving 0.3\% peak non-linearity, 6.1 e-rms random noise (RN), and 67-dB dynamic range. The power consumption is only 2.1 mW at 44 frames per second (fps) and is further reduced to 140 $\mu$W at 5 fps with the subsampled 320 × 320 mode. This sensor achieves a state-of-the-art energy efﬁciency ﬁgure-of-merit of 0.71 e-·nJ.},
	language = {en},
	number = {4},
	urldate = {2022-06-08},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Park, Injun and Jo, Woojin and Park, Chanmin and Park, Byungchoul and Cheon, Jimin and Chae, Youngcheol},
	month = apr,
	year = {2020},
	pages = {898--907},
	file = {Park et al. - 2020 - A 640 \$times\$ 640 Fully Dynamic CMOS Image Sensor.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\MUFS8YKL\\Park et al. - 2020 - A 640 \$times\$ 640 Fully Dynamic CMOS Image Sensor.pdf:application/pdf},
}

@article{zhao_reinforcement-learning-based_2022,
	title = {A {Reinforcement}-{Learning}-{Based} {Energy}-{Efficient} {Framework} for {Multi}-{Task} {Video} {Analytics} {Pipeline}},
	volume = {24},
	issn = {1520-9210, 1941-0077},
	url = {https://ieeexplore.ieee.org/document/9420287/},
	doi = {10.1109/TMM.2021.3076612},
	abstract = {Deep-learning-based video processing has yielded transformative results in recent years. However, the video analytics pipeline is energy-intensive due to high data rates and reliance on complex inference algorithms, which limits its adoption in energy-constrained applications. Motivated by the observation of high and variable spatial redundancy and temporal dynamics in video data streams, we design and evaluate an adaptiveresolution optimization framework to minimize the energy use of multi-task video analytics pipelines. Instead of heuristically tuning the input data resolution of individual tasks, our framework utilizes deep reinforcement learning to dynamically govern the input resolution and computation of the entire video analytics pipeline. By monitoring the impact of varying resolution on the quality of high-dimensional video analytics features, hence the accuracy of video analytics results, the proposed end-to-end optimization framework learns the best non-myopic policy for dynamically controlling the resolution of input video streams to globally optimize energy efﬁciency. Governed by reinforcement learning, optical ﬂow is incorporated into the framework to minimize unnecessary spatio-temporal redundancy that leads to recomputation, while preserving accuracy. The proposed framework is applied to video instance segmentation which is one of the most challenging computer vision tasks, and achieves better energy efﬁciency than all baseline methods of similar accuracy on the YouTube-VIS dataset.},
	language = {en},
	urldate = {2022-06-09},
	journal = {IEEE Transactions on Multimedia},
	author = {Zhao, Yingying and Dong, Mingzhi and Wang, Yujiang and Feng, Da and Lv, Qin and Dick, Robert P. and Li, Dongsheng and Lu, Tun and Gu, Ning and Shang, Li},
	year = {2022},
	pages = {2150--2163},
	file = {Zhao et al. - 2022 - A Reinforcement-Learning-Based Energy-Efficient Fr.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\E2HTPNAJ\\Zhao et al. - 2022 - A Reinforcement-Learning-Based Energy-Efficient Fr.pdf:application/pdf},
}

@article{chen_12_2014,
	title = {A 12 {pJ}/{Pixel} {Analog}-to-{Information} {Converter} {Based} 816 × 640 {Pixel} {CMOS} {Image} {Sensor}},
	volume = {49},
	issn = {0018-9200, 1558-173X},
	url = {http://ieeexplore.ieee.org/document/6762815/},
	doi = {10.1109/JSSC.2014.2307063},
	abstract = {Analog-to-information converters (AICs) take advantage of the limited information bandwidth in high-frequency signals to improve the energy efﬁciency of front-end data converters. High-resolution image sensors often convey limited information due to the spatial redundancy between neighboring pixels. This paper proposes a mixed-signal AIC which compresses each nonoverlapping 4 × 4 pixel block in a 816 × 640 pixel prototype active-pixel sensor (APS) imager. It combines an energy-efﬁcient charge-pump bit-image processor (BIP) with an area-efﬁcient successive-approximation-register-single-slope (SAR-SS) hybrid analog-to-digital converter (ADC) via a charge-transfer-ampliﬁer (CTA). The AIC is fully dynamic and consumes no static power. The ADC’s capacitor array doubles as a computational device for parts of the compression algorithm which reduces its sampling rate by a factor of four. The compressed data contains direct edge information and can be decoded by a very simple receiver. The fabricated prototype consumes 12 pJ per pixel at 111 fps in the image compression mode and 48 pJ per pixel at 28.7 fps in raw data mode (9 b per pixel) under the same clock rate. To the best of our knowledge, this is the most energy-efﬁcient compressive CMOS image sensor ever reported in the literature, thanks to the proposed AIC.},
	language = {en},
	number = {5},
	urldate = {2022-06-09},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Chen, Denis Guangyin and Tang, Fang and Law, Man-Kay and Bermak, Amine},
	month = may,
	year = {2014},
	pages = {1210--1222},
	file = {Chen et al. - 2014 - A 12 pJPixel Analog-to-Information Converter Base.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\MWMCA3NG\\Chen et al. - 2014 - A 12 pJPixel Analog-to-Information Converter Base.pdf:application/pdf},
}

@inproceedings{funatsu_62_2015,
	address = {San Francisco, CA, USA},
	title = {6.2 {133Mpixel} 60fps {CMOS} image sensor with 32-column shared high-speed column-parallel {SAR} {ADCs}},
	isbn = {978-1-4799-6223-5 978-1-4799-6224-2},
	url = {http://ieeexplore.ieee.org/document/7062951/},
	doi = {10.1109/ISSCC.2015.7062951},
	language = {en},
	urldate = {2022-06-09},
	booktitle = {2015 {IEEE} {International} {Solid}-{State} {Circuits} {Conference} - ({ISSCC}) {Digest} of {Technical} {Papers}},
	publisher = {IEEE},
	author = {Funatsu, Ryohei and Huang, Steven and Yamashita, Takayuki and Stevulak, Kevin and Rysinski, Jeff and Estrada, David and Yan, Shi and Soeno, Takuji and Nakamura, Tomohiro and Hayashida, Tetsuya and Shimamoto, Hiroshi and Mansoorian, Barmak},
	month = feb,
	year = {2015},
	pages = {1--3},
	file = {Funatsu et al. - 2015 - 6.2 133Mpixel 60fps CMOS image sensor with 32-colu.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\JRJKMNS3\\Funatsu et al. - 2015 - 6.2 133Mpixel 60fps CMOS image sensor with 32-colu.pdf:application/pdf},
}

@article{choi_energyillumination-adaptive_2015,
	title = {An {Energy}/{Illumination}-{Adaptive} {CMOS} {Image} {Sensor} {With} {Reconfigurable} {Modes} of {Operations}},
	volume = {50},
	issn = {0018-9200, 1558-173X},
	url = {http://ieeexplore.ieee.org/document/7095624/},
	doi = {10.1109/JSSC.2015.2420678},
	language = {en},
	number = {6},
	urldate = {2022-06-10},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Choi, Jaehyuk and Park, Seokjun and Cho, Jihyun and Yoon, Euisik},
	month = jun,
	year = {2015},
	pages = {1438--1450},
	file = {Choi et al. - 2015 - An EnergyIllumination-Adaptive CMOS Image Sensor .pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\B39LF3AN\\Choi et al. - 2015 - An EnergyIllumination-Adaptive CMOS Image Sensor .pdf:application/pdf},
}

@article{takayanagi_125-inch_2005,
	title = {A 1.25-inch 60-frames/s 8.3-{M}-pixel digital-output {CMOS} image sensor},
	volume = {40},
	issn = {0018-9200},
	url = {http://ieeexplore.ieee.org/document/1522570/},
	doi = {10.1109/JSSC.2005.857375},
	abstract = {The ultrahigh-deﬁnition television (UDTV) camera system requires an image sensor having four times higher resolution and two times higher frame rate than the conventional HDTV systems. Also, an image sensor with a small optical format and low power consumption is required for practical UDTV camera systems. To respond to these requirements, we have developed an 8.3-M-pixel digital-output CMOS active pixel sensor (APS) for the UDTV application. It features an optical format of 1.25 inch, low power consumption of less than 600 mW at dark, while reproducing a low-noise, 60-frames/s progressive scan image. The image sensor is equipped with 1920 on-chip 10-bit analog-to-digital converters and outputs digital data stream through 16 parallel output ports. Design considerations to reproduce a low-noise, high-resolution image at high frame rate of 60 fps are described. Implementation and experimental results of the 8.3-M-pixel CMOS APS are presented.},
	language = {en},
	number = {11},
	urldate = {2022-06-10},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Takayanagi, I. and Shirakawa, M. and Mitani, K. and Sugawara, M. and Iversen, S. and Moholt, J. and Nakamura, J. and Fossum, E.R.},
	month = nov,
	year = {2005},
	pages = {2305--2314},
	file = {Takayanagi et al. - 2005 - A 1.25-inch 60-framess 8.3-M-pixel digital-output.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\AFNL3ZFA\\Takayanagi et al. - 2005 - A 1.25-inch 60-framess 8.3-M-pixel digital-output.pdf:application/pdf},
}

@article{kitamura_33-megapixel_2012,
	title = {A 33-{Megapixel} 120-{Frames}-{Per}-{Second} 2.5-{Watt} {CMOS} {Image} {Sensor} {With} {Column}-{Parallel} {Two}-{Stage} {Cyclic} {Analog}-to-{Digital} {Converters}},
	volume = {59},
	issn = {0018-9383, 1557-9646},
	url = {http://ieeexplore.ieee.org/document/6341066/},
	doi = {10.1109/TED.2012.2220364},
	language = {en},
	number = {12},
	urldate = {2022-06-10},
	journal = {IEEE Transactions on Electron Devices},
	author = {Kitamura, Kazuya and Watabe, Toshihisa and Sawamoto, Takehide and Kosugi, Tomohiko and Akahori, Tomoyuki and Iida, Tetsuya and Isobe, Keigo and Watanabe, Takashi and Shimamoto, Hiroshi and Ohtake, Hiroshi and Aoyama, Satoshi and Kawahito, Shoji and Egami, Norifumi},
	month = dec,
	year = {2012},
	pages = {3426--3433},
	file = {Kitamura et al. - 2012 - A 33-Megapixel 120-Frames-Per-Second 2.5-Watt CMOS.pdf:C\:\\Users\\lwzz0\\Zotero\\storage\\RW44A3SJ\\Kitamura et al. - 2012 - A 33-Megapixel 120-Frames-Per-Second 2.5-Watt CMOS.pdf:application/pdf},
}
